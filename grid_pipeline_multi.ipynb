{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# %%writefile file_name.py\n",
    "# %load file_name.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "The first step is to load our sample data for both spam and ham. For this, we created a utility called loader which, given an input file path, reads the content from the file and append it to a python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load train_server/utils/csv.py\n",
    "import pandas as pd\n",
    "\n",
    "def to_csv(file_name, features, labels):\n",
    "    df = pd.DataFrame({'features': features,\n",
    "                       'labels': labels})\n",
    "    df.to_csv('{}'.format(file_name))\n",
    "    print('Wrote to {}'.format(file_name))\n",
    "\n",
    "def read_csv(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    X = df.as_matrix(columns = ['features']).flatten()\n",
    "    y = df.as_matrix(columns = ['labels']).astype(str).flatten()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load train_server/pipeline/array_transformer.py\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ArrayTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load train_server/pipeline/nltk_preprocessor.py\n",
    "import os\n",
    "import re\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip = True, stem = True, symbols = True, stemmer = None):\n",
    "        self.strip = strip\n",
    "        self.stem = stem\n",
    "        self.symbols = symbols\n",
    "        self.stemmer = stemmer or PorterStemmer()\n",
    "        self.pattern = re.compile(r'\\W')\n",
    "        \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        with ProcessPoolExecutor(max_workers = os.cpu_count() * 5) as executor:\n",
    "            futures = [executor.submit(self.tokenize, X_i) for X_i in X]\n",
    "            X_out = [future.result() for future in futures]\n",
    "            return X_out\n",
    "\n",
    "    def tokenize(self, sentence):\n",
    "        words = word_tokenize(sentence)\n",
    "        out = []\n",
    "        for word in words:\n",
    "            if self.symbols and self.pattern.search(word):\n",
    "                continue\n",
    "            word = word.strip() if self.strip else word\n",
    "            word = self.stemmer.stem(word) if self.stem else word\n",
    "            out.append(word)\n",
    "        return ' '.join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5172,) (5172,) Subject: what up , , your cam babe\n",
      "what are you looking for ?\n",
      "if your looking for a companion for friendship , love , a date , or just good ole '\n",
      "fashioned * * * * * * , then try our brand new site ; it was developed and created\n",
      "to help anyone find what they ' re looking for . a quick bio form and you ' re\n",
      "on the road to satisfaction in every sense of the word . . . . no matter what\n",
      "that may be !\n",
      "try it out and youll be amazed .\n",
      "have a terrific time this evening\n",
      "copy and pa ste the add . ress you see on the line below into your browser to come to the site .\n",
      "http : / / www . meganbang . biz / bld / acc /\n",
      "no more plz\n",
      "http : / / www . naturalgolden . com / retract /\n",
      "counterattack aitken step preemptive shoehorn scaup . electrocardiograph movie honeycomb . monster war brandywine pietism byrne catatonia . encomia lookup intervenor skeleton turn catfish .\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "X, y = read_csv('train_server/data.csv')\n",
    "print(X.shape, y.shape, X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load train_server/classifiers.py\n",
    "def linear_svc_clf():\n",
    "    from sklearn.svm import LinearSVC\n",
    "    \n",
    "    estimators = [('linear_svc', LinearSVC())]\n",
    "    param_grid = dict(linear_svc__C = [1, 10, 100],\n",
    "                      linear_svc__random_state = [42],\n",
    "                      linear_svc__max_iter = [1000, 10000])\n",
    "\n",
    "    return estimators, param_grid\n",
    "\n",
    "def multinomial_nb_clf():\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    estimators = [('multinomial_nb', MultinomialNB())]\n",
    "    param_grid = dict(multinomial_nb__alpha = [1, 10, 100],\n",
    "                      multinomial_nb__fit_prior = [True],\n",
    "                      multinomial_nb__class_prior = [None])\n",
    "\n",
    "    return estimators, param_grid\n",
    "\n",
    "def random_forest_clf():\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    estimators = [('random_forest', RandomForestClassifier())]\n",
    "    param_grid = dict(random_forest__n_estimators = [10, 20, 30],\n",
    "                      random_forest__criterion = ['gini', 'entropy'],\n",
    "                      random_forest__max_features = ['auto', 'sqrt', 'log2'],\n",
    "#                       random_forest__max_depth = [None],\n",
    "                      random_forest__min_samples_split = [2],\n",
    "                      random_forest__min_samples_leaf = [1],\n",
    "                      random_forest__min_weight_fraction_leaf = [0],\n",
    "                      random_forest__max_leaf_nodes = [None],\n",
    "                      random_forest__min_impurity_decrease = [0],\n",
    "                      random_forest__bootstrap = [True],\n",
    "                      random_forest__oob_score = [False],\n",
    "                      random_forest__n_jobs = [-1],\n",
    "                      random_forest__random_state = [42],\n",
    "                      random_forest__warm_start = [False],\n",
    "                      random_forest__class_weight = ['balanced'])\n",
    "\n",
    "    return estimators, param_grid\n",
    "\n",
    "def gaussian_nb_clf():\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    \n",
    "    estimators = [('gaussian_nb', GaussianNB())]\n",
    "    param_grid = dict()\n",
    "    return estimators, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Classifier name: gaussian_nb\n",
      "Best params:\n",
      " {} \n",
      "\n",
      "Classifier results:\n",
      " {'mean_fit_time': array([ 10.05631177]), 'std_fit_time': array([ 0.67966023]), 'mean_score_time': array([ 5.20344122]), 'std_score_time': array([ 0.14778877]), 'params': [{}], 'split0_test_score': array([ 0.94978355]), 'split1_test_score': array([ 0.94199134]), 'split2_test_score': array([ 0.94978355]), 'mean_test_score': array([ 0.94718615]), 'std_test_score': array([ 0.00367328]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([ 0.98787879]), 'split1_train_score': array([ 0.98787879]), 'split2_train_score': array([ 0.98787879]), 'mean_train_score': array([ 0.98787879]), 'std_train_score': array([ 0.])} \n",
      "\n",
      "Confusion matrix:\n",
      " [[1136   55]\n",
      " [  40  476]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96      1191\n",
      "          1       0.90      0.92      0.91       516\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1707\n",
      "\n",
      "End\n",
      "model saved as models/gaussian_nb.pkl\n"
     ]
    }
   ],
   "source": [
    "classifiers = [# linear_svc_clf(),\n",
    "               # multinomial_nb_clf(),\n",
    "               # random_forest_clf(),\n",
    "               gaussian_nb_clf()]\n",
    "\n",
    "labels = ['0', '1']\n",
    "\n",
    "def build_model(estimators, param_grid):\n",
    "    clf_name = estimators[0][0]\n",
    "    print('Start')\n",
    "    print('Classifier name: {}'.format(clf_name))\n",
    "    \n",
    "    pipeline_estimators = [('nltk_preprocessor', NLTKPreprocessor()),\n",
    "                           ('vectorizer', CountVectorizer(stop_words = 'english')),\n",
    "                           ('tfidf', TfidfTransformer()),\n",
    "                           ('transformer', ArrayTransformer()),\n",
    "                           estimators[0]]\n",
    "    \n",
    "    pipeline = Pipeline(pipeline_estimators)\n",
    "    clf = GridSearchCV(pipeline, param_grid = param_grid)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best params:\\n', clf.best_params_, '\\n')\n",
    "    print('Classifier results:\\n', clf.cv_results_, '\\n')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_true = y_test, \n",
    "                          y_pred = y_pred, \n",
    "                          labels = labels)\n",
    "    print('Confusion matrix:\\n', cm)\n",
    "    report = classification_report(y_test, \n",
    "                                   y_pred, \n",
    "                                   target_names = labels)\n",
    "    \n",
    "    # Save model\n",
    "    print('Classification report:\\n', report)\n",
    "    print('End')\n",
    "    return clf_name, clf\n",
    "\n",
    "results = [build_model(estimators, param_grid) \n",
    "           for (estimators, param_grid) in classifiers]\n",
    "\n",
    "for (clf_name, clf) in results:\n",
    "    joblib.dump(clf, 'models/{}.pkl'.format(clf_name)) \n",
    "    print('model saved as models/{}.pkl'.format(clf_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clf = joblib.load('gaussian_nb.pkl')\n",
    "# # clf = joblib.load('random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features = ['sexy babe', 'hello world']\n",
    "# clf.predict(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
