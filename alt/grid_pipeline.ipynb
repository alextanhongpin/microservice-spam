{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.classify.naivebayes import NaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# Todo: There is snowball stemmer too\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "The first step is to load our sample data for both spam and ham. For this, we created a utility called loader which, given an input file path, reads the content from the file and append it to a python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loader(file_input):\n",
    "    data = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(file_input):\n",
    "        for file in filenames:\n",
    "            path = os.path.join(dirpath, file)\n",
    "            with open(path, encoding='latin-1') as f:\n",
    "                data.append(f.read())\n",
    "                f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_input = './data/enron1/ham'\n",
    "ham = loader(file_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_input = './data/enron1/spam'\n",
    "spam = loader(file_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "patt = re.compile(r'\\W')\n",
    "stops = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def process_words(data):\n",
    "    words = word_tokenize(data)\n",
    "    \n",
    "    # Lowercase\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stops]\n",
    "\n",
    "    # Remove special characters\n",
    "    words = [word for word in words if not patt.search(word)]\n",
    "\n",
    "    # Remove digit\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "    \n",
    "    # Strip\n",
    "    words = [word.strip() for word in words]\n",
    "\n",
    "    # Stem words\n",
    "    words = [ps.stem(word) for word in words]\n",
    "    \n",
    "#     return dict([(word, True) for word in words])\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "ham_data = [(process_words(words), 0) for words in ham] # 0 for ham\n",
    "spam_data = [(process_words(words), 1) for words in spam] # 1 for spam\n",
    "all_data = spam_data + ham_data\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = np.array(all_data)\n",
    "X = all_data[:, 0]\n",
    "y = all_data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=3000)\n",
    "X = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [('clf', LinearSVC())]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = dict(clf__C = [1, 10, 100],\n",
    "                  clf__random_state = [42],\n",
    "                  clf__max_iter = [1000, 10000])\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1, 'clf__max_iter': 1000, 'clf__random_state': 42}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best parameters set found on development set:')\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on development set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__max_iter</th>\n",
       "      <th>param_clf__random_state</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.495874</td>\n",
       "      <td>1.201997</td>\n",
       "      <td>0.954978</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.947186</td>\n",
       "      <td>0.955844</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.764956</td>\n",
       "      <td>0.136037</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.130771</td>\n",
       "      <td>1.050004</td>\n",
       "      <td>0.954978</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.947186</td>\n",
       "      <td>0.955844</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.311174</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.855962</td>\n",
       "      <td>1.002008</td>\n",
       "      <td>0.946898</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.941126</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.951515</td>\n",
       "      <td>0.237287</td>\n",
       "      <td>0.027871</td>\n",
       "      <td>0.004319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.966587</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>0.946898</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.941126</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.951515</td>\n",
       "      <td>0.251720</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>0.004319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.661111</td>\n",
       "      <td>0.922435</td>\n",
       "      <td>0.945743</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.940260</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.951515</td>\n",
       "      <td>0.059258</td>\n",
       "      <td>0.025758</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.842381</td>\n",
       "      <td>0.929047</td>\n",
       "      <td>0.945743</td>\n",
       "      <td>100</td>\n",
       "      <td>10000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.940260</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.951515</td>\n",
       "      <td>0.115369</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score param_clf__C  \\\n",
       "0       2.495874         1.201997         0.954978            1   \n",
       "1       2.130771         1.050004         0.954978            1   \n",
       "2       1.855962         1.002008         0.946898           10   \n",
       "3       1.966587         0.972643         0.946898           10   \n",
       "4       1.661111         0.922435         0.945743          100   \n",
       "5       1.842381         0.929047         0.945743          100   \n",
       "\n",
       "  param_clf__max_iter param_clf__random_state  split0_test_score  \\\n",
       "0                1000                      42           0.947186   \n",
       "1               10000                      42           0.947186   \n",
       "2                1000                      42           0.941126   \n",
       "3               10000                      42           0.941126   \n",
       "4                1000                      42           0.940260   \n",
       "5               10000                      42           0.940260   \n",
       "\n",
       "   split1_test_score  split2_test_score  std_fit_time  std_score_time  \\\n",
       "0           0.955844           0.961905      0.764956        0.136037   \n",
       "1           0.955844           0.961905      0.311174        0.004181   \n",
       "2           0.948052           0.951515      0.237287        0.027871   \n",
       "3           0.948052           0.951515      0.251720        0.030333   \n",
       "4           0.945455           0.951515      0.059258        0.025758   \n",
       "5           0.945455           0.951515      0.115369        0.013006   \n",
       "\n",
       "   std_test_score  \n",
       "0        0.006040  \n",
       "1        0.006040  \n",
       "2        0.004319  \n",
       "3        0.004319  \n",
       "4        0.004600  \n",
       "5        0.004600  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Grid scores on development set:')\n",
    "df = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "\n",
    "df = df[['mean_fit_time', \n",
    "         'mean_score_time',\n",
    "         'mean_test_score',\n",
    "         'param_clf__C',\n",
    "         'param_clf__max_iter',\n",
    "         'param_clf__random_state',\n",
    "         'split0_test_score',\n",
    "         'split1_test_score',\n",
    "         'split2_test_score',\n",
    "         'std_fit_time',\n",
    "         'std_score_time',\n",
    "         'std_test_score'\n",
    "        ]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1'], \n",
       "      dtype='<U20041')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'fake babe is amazing'\n",
    "text_data = vectorizer.transform([process_words(text)]).toarray()\n",
    "clf.predict(text_data)\n",
    "# text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1'], \n",
       "      dtype='<U20041')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'hello world'\n",
    "text_data = vectorizer.transform([process_words(text)]).toarray()\n",
    "clf.predict(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '1', ..., '0', '1', '0'], \n",
       "      dtype='<U20041')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 490,   26],\n",
       "       [  37, 1154]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true = y_test, \n",
    "                 y_pred = y_pred, \n",
    "                 labels = ['1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.97      1191\n",
      "          1       0.93      0.95      0.94       516\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['0', '1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
